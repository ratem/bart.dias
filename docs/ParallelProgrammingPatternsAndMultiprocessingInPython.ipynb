{"cells":[{"cell_type":"markdown","metadata":{"id":"389bdf46-dfb9-4d8d-a155-761f879031cf"},"source":["# Introduction to Parallel Programming Patterns and Multiprocessing in Python\n","\n","Hands on Parallel Computing for Data Science, Machine Learning and Artificial\n","Intelligence.<br>  \n","## Contents  \n","A) Quick Theoretical Background:  \n","0- Introduction  \n","1- Fundamentals of Parallel Computing and Multiprocessing  \n","2- Threading vs. multiprocessing\n","3- Parallel Programming Patterns for Data Processing and Analysis  \n","B) Practice  \n","4- Python’s multiprocessing module and its capabilities  \n","5- Parallel programming patterns for data processing and analysis in Python Multiprocessing\n","C) Advanced Topics  \n","6- Multiprocessing in Machine Learning and AI  \n","7- Best practices and performance optimization techniques  \n","8- Distributed computing frameworks for large-scale AI applications  \n","9- Quick real-world case studies and practical examples\n","\n","## A) Quick Theoretical Background:\n","\n","### 1. Fundamentals of Parallel Computing and Multiprocessing\n","\n","Parallel computing is a computational paradigm that breaks down large\n","problems into smaller tasks that can be executed simultaneously. This\n","approach leverages multiple processing units to solve complex problems\n","more efficiently than sequential processing. Key concepts in parallel\n","computing include:\n","\n","-   **Parallelism**: The ability to perform multiple computations     simultaneously.\n","-   **Concurrency**: The ability to progress multiple tasks over     overlapping time periods.\n","\n","Types of parallelism:\n","\n","1.  **Bit-level parallelism**: Increasing word size to reduce the number of instructions.\n","2.  **Instruction-level parallelism**: Executing multiple instructions     simultaneously.\n","3.  **Data parallelism**: Distributing data across multiple processing     units.\n","4.  **Task parallelism**: Distributing tasks across multiple processing    units.\n","\n","Parallel computing architectures:\n","\n","1.  **Shared memory systems**: Multiple processors access the same memory space.\n","2.  **Distributed memory systems**: Each processor has its own private  memory.\n","3.  **Hybrid systems**: Combination of shared and distributed memory    architectures.\n","\n","Multiprocessing is a specific form of parallel computing that utilizes multiple processors or cores within a single computer system. It allows for true parallelism by distributing tasks across different CPU cores.\n","\n","### Concurrency X Parallelism: Fundamental differences\n","\n","Concurrency and parallelism are two fundamental concepts in Computer Science that deal with executing multiple tasks, but they have distinct characteristics and implementations. Let’s explore the key differences between these two concepts:\n","\n","#### Definitions\n","\n","**Concurrency** refers to the ability of a system to handle multiple tasks by switching between them, giving the illusion of simultaneous execution\n","[1](https://stackoverflow.com/questions/1050222/what-is-the-difference-between-concurrency-and-parallelism)\n","[5](https://oxylabs.io/blog/concurrency-vs-parallelism). It’s about managing and making progress on multiple tasks over overlapping time periods, even if they’re not actually running at the same instant\n","[1](https://stackoverflow.com/questions/1050222/what-is-the-difference-between-concurrency-and-parallelism)\n","[2](https://www.studysmarter.co.uk/explanations/computer-science/computer-programming/concurrency-vs-parallelism/). <br>\n","**Parallelism**, on the other hand, involves the actual simultaneous\n","execution of multiple tasks or parts of a task\n","[1](https://stackoverflow.com/questions/1050222/what-is-the-difference-between-concurrency-and-parallelism)\n","[2](https://www.studysmarter.co.uk/explanations/computer-science/computer-programming/concurrency-vs-parallelism/).\n","It requires multiple processing units (like CPU cores) to perform tasks\n","truly concurrently\n","[4](https://brightdata.com/blog/web-data/concurrency-vs-parallelism).\n","\n","#### Execution Model\n","\n","**Concurrency:**\n","\n","-   Tasks start, run, and complete in overlapping time periods [1](https://stackoverflow.com/questions/1050222/what-is-the-difference-between-concurrency-and-parallelism).\n","-   The system rapidly switches between tasks, creating an illusion of     simultaneous execution [2](https://www.studysmarter.co.uk/explanations/computer-science/computer-programming/concurrency-vs-parallelism/).\n","-   Can be achieved on a single-core processor through time-slicing [1](https://stackoverflow.com/questions/1050222/what-is-the-difference-between-concurrency-and-parallelism) [2](https://www.studysmarter.co.uk/explanations/computer-science/computer-programming/concurrency-vs-parallelism/).\n","\n","**Parallelism:**\n","\n","-   Tasks literally run at the same time on different processing units [1](https://stackoverflow.com/questions/1050222/what-is-the-difference-between-concurrency-and-parallelism).\n","-   Requires multi-core processors or distributed systems [2](https://www.studysmarter.co.uk/explanations/computer-science/computer-programming/concurrency-vs-parallelism/).\n","-   Tasks start, run, and complete simultaneously [2](https://www.studysmarter.co.uk/explanations/computer-science/computer-programming/concurrency-vs-parallelism/).\n","\n","#### Resource Utilization\n","\n","**Concurrency:**\n","\n","-   Focuses on efficient management of shared resources [4](https://brightdata.com/blog/web-data/concurrency-vs-parallelism).\n","-   Utilizes a single core by interleaving task execution [4](https://brightdata.com/blog/web-data/concurrency-vs-parallelism).\n","-   Aims to maximize CPU usage during idle or waiting periods [4](https://brightdata.com/blog/web-data/concurrency-vs-parallelism).\n","\n","**Parallelism:**\n","\n","-   Utilizes multiple cores or processors to execute tasks simultaneously [4](https://brightdata.com/blog/web-data/concurrency-vs-parallelism).\n","-   Focuses on distributing workload across available processing units [4](https://brightdata.com/blog/web-data/concurrency-vs-parallelism).\n","\n","#### Implementation\n","\n","**Concurrency:**\n","\n","-   Often implemented using threading in programming languages [5](https://oxylabs.io/blog/concurrency-vs-parallelism).\n","-   Requires careful management of shared resources and synchronization [1](https://stackoverflow.com/questions/1050222/what-is-the-difference-between-concurrency-and-parallelism).\n","\n","**Parallelism:**\n","\n","-   Implemented using multiprocessing or distributed computing techniques [5](https://oxylabs.io/blog/concurrency-vs-parallelism).\n","-   Focuses on task decomposition and load balancing across processing units  [2](https://www.studysmarter.co.uk/explanations/computer-science/computer-programming/concurrency-vs-parallelism/).\n","\n","#### Focus and Goal\n","\n","**Concurrency:**\n","\n","-   Deals with managing and coordinating multiple tasks [4](https://brightdata.com/blog/web-data/concurrency-vs-parallelism).\n","-   Aims to improve responsiveness and resource utilization [2](https://www.studysmarter.co.uk/explanations/computer-science/computer-programming/concurrency-vs-parallelism/).\n","\n","**Parallelism:**\n","\n","-   Focuses on simultaneous execution to improve performance [4](https://brightdata.com/blog/web-data/concurrency-vs-parallelism).\n","-   Aims to reduce overall execution time by distributing workload [2](https://www.studysmarter.co.uk/explanations/computer-science/computer-programming/concurrency-vs-parallelism/).\n","\n","In practice, modern systems often combine both concurrency and parallelism to achieve optimal performance and resource utilization. This combination is sometimes referred to as “Parallel Concurrent Execution,” where multiple CPUs run multiple threads concurrently and in parallel [5](https://oxylabs.io/blog/concurrency-vs-parallelism). <br>\n","Understanding these fundamental differences is crucial for designing\n","efficient and scalable systems, especially in areas like web scraping,\n","where both concepts can be leveraged to improve performance and handle\n","multiple tasks effectively [5](https://oxylabs.io/blog/concurrency-vs-parallelism).\n","\n","\n","### 2. Threading vs. multiprocessing\n","\n","Threading and multiprocessing are two approaches to achieve concurrent\n","execution. <br>\n","Threading:\n","-   Lightweight processes that share the same memory space.\n","-   Suitable for I/O-bound tasks (e.g., network operations, file I/O).\n","-   Limited by the Global Interpreter Lock (GIL) in CPython.\n","-   Easier to implement and manage shared state.\n","\n","Multiprocessing:\n","-   Separate processes with independent memory spaces.\n","-   Suitable for CPU-bound tasks (e.g., complex computations).\n","-   Bypasses the GIL limitation.\n","-   Requires more careful management of shared state.\n","When to use threading:\n","-   I/O-bound tasks\n","-   Tasks that require frequent communication or shared state\n","-   When memory usage is a concern\n","When to use multiprocessing:\n","-   CPU-bound tasks\n","-   Tasks that require true parallelism\n","-   When isolation between tasks is important\n","\n","#### 2.1 The Global Interpreter Lock (GIL)\n","\n","The Global Interpreter Lock (GIL) is a crucial component of CPython, the most widely-used implementation of Python, that significantly impacts the execution of multi-threaded Python programs. The GIL is essentially a mutex that allows only one thread to execute Python bytecode at a time, even on multi-core processors [1](https://wiki.python.org/moin/GlobalInterpreterLock). <br>\n","\n","The GIL was introduced to simplify memory management and ensure thread safety in CPython, protecting access to Python objects and preventing race conditions, particularly in reference counting for memory management. While it enhances stability and simplifies the interpreter's design, it comes with trade-offs, being the main, impact on performance. CPU and I/O bound tasks.\n","\n","##### Impact on CPU-bound Tasks\n","The GIL's most significant impact is on CPU-bound multi-threaded programs. Let's consider an example:\n","\n","```python\n","import time\n","from threading import Thread\n","\n","COUNT = 50000000\n","\n","def countdown(n):\n","    while n > 0:\n","        n -= 1\n","\n","t1 = Thread(target=countdown, args=(COUNT//2,))\n","t2 = Thread(target=countdown, args=(COUNT//2,))\n","\n","start = time.time()\n","t1.start()\n","t2.start()\n","t1.join()\n","t2.join()\n","end = time.time()\n","\n","print('Time taken in seconds -', end - start)\n","```\n","\n","In this CPU-bound task, despite using two threads, the program won't run significantly faster than a single-threaded version due to the GIL. Both threads compete for the GIL, preventing true parallelism.\n","\n","##### Impact on I/O-bound Tasks\n","For I/O-bound tasks, the GIL's impact is less severe. Python releases the GIL during I/O operations, allowing other threads to run. Here's an example:\n","\n","```python\n","import asyncio\n","import aiohttp\n","\n","async def fetch_url(url):\n","    async with aiohttp.ClientSession() as session:\n","        async with session.get(url) as response:\n","            return await response.text()\n","\n","async def main():\n","    urls = ['http://example.com', 'http://example.org', 'http://example.net']\n","    tasks = [fetch_url(url) for url in urls]\n","    results = await asyncio.gather(*tasks)\n","    for url, result in zip(urls, results):\n","        print(f\"Fetched {len(result)} bytes from {url}\")\n","\n","asyncio.run(main())\n","```\n","\n","This asynchronous I/O example can effectively utilize multiple threads, as the GIL is released during network operations [2](https://dev.to/adityabhuyan/understanding-pythons-global-interpreter-lock-gil-and-its-impact-on-concurrency-2da6).\n","\n","##### Workarounds and Solutions\n","\n","1.  **Multiprocessing**: For CPU-bound tasks, using the `multiprocessing` module can bypass the GIL by using separate Python processes.\n","2.  **C Extensions**: CPU-intensive operations can be implemented as C extensions, which can release the GIL and achieve true parallelism.\n","3.  **Asynchronous Programming**: For I/O-bound tasks, async programming (using `asyncio`) can efficiently handle concurrency without the need for multiple threads.\n","4.  **Alternative Python Implementations**: Some Python implementations, like Jython or IronPython, don't have a GIL, allowing true multi-threading.\n","\n","While the GIL simplifies Python's internals and memory management, it presents challenges for CPU-bound multi-threaded applications. Understanding its behavior is crucial for optimizing Python programs, especially when dealing with concurrency and parallelism. For many applications, particularly I/O-bound ones, the GIL's impact is minimal, and Python remains an excellent choice with its rich ecosystem and ease of use.\n","\n","**Sources:**\n","- [(1) GlobalInterpreterLock - Python Wiki](https://wiki.python.org/moin/GlobalInterpreterLock)\n","- [(2) Understanding Python's Global Interpreter Lock (GIL) and Its Impact](https://dev.to/adityabhuyan/understanding-pythons-global-interpreter-lock-gil-and-its-impact-on-concurrency-2da6)\n","\n","\n","### 3. Parallel Programming Patterns for Data Processing and Analysis\n","Parallel programming patterns provide reusable solutions for common\n","parallel computing problems. These patterns help in structuring parallel\n","algorithms and improving code organization.\n","\n","1.  **Map-Reduce Pattern**:\n","    -   Map: Apply a function to each element in a dataset.\n","    -   Reduce: Combine the results into a single output.\n","2.  **Fork-Join Pattern**:\n","    -   Fork: Split a task into smaller subtasks.\n","    -   Join: Combine the results of subtasks.\n","3.  **Pipeline Pattern**:\n","\n","    -   Divide a task into a series of stages.\n","    -   Each stage processes data and passes it to the next stage.\n","4.  **Master-Worker Pattern**:\n","\n","    -   Master process distributes tasks to worker processes.\n","    -   Workers perform computations and return results to the master.\n","5.  **Divide and Conquer Pattern**:\n","    -   Recursively break down a problem into smaller subproblems.\n","    -   Solve subproblems independently and combine results.\n","6.  **Stencil Pattern**:\n","    -   Update array elements based on neighboring elements.\n","    -   Common in image processing and scientific simulations.\n","7.  **Scatter-Gather Pattern**:\n","    -   Scatter: Distribute data across multiple processes.\n","    -   Gather: Collect results from all processes.\n","\n","These patterns can be applied to various data processing and analysis\n","tasks, such as:\n","\n","-   Large-scale data transformations\n","-   Parallel sorting and searching algorithms\n","-   Distributed machine learning model training\n","-   Parallel matrix operations\n","-   Parallel graph algorithms\n","\n","## B) Practice:\n","\n","### 4. Python’s multiprocessing module and its capabilities\n","Python’s multiprocessing module provides a powerful interface for parallel processing. Let’s quickly explore its key features and capabilities:\n","\n","``` python\n","import multiprocessing as mp\n","import time\n","\n","def worker(num):\n","    \"\"\"Simple worker function\"\"\"\n","    print(f\"Worker {num} started\")\n","    time.sleep(2)\n","    print(f\"Worker {num} finished\")\n","\n","if __name__ == '__main__':\n","    # Create a pool of worker processes\n","    pool = mp.Pool(processes=4)\n","\n","   # Map the worker function to a range of inputs\n","    pool.map(worker, range(8))\n","\n","   # Close the pool and wait for all processes to finish\n","    pool.close()\n","    pool.join()\n","```\n","\n","Key capabilities of the multiprocessing module:\n","1. **Process creation and management**:\n","``` python\n","    p = mp.Process(target=worker, args=(1,))\n","    p.start()\n","    p.join()`\n","```\n","2. **Pool of worker processes**:\n","```python\n","   with mp.Pool(processes=4) as pool:\n","    results = pool.map(worker, range(8))`\n","```\n","3.  **Shared\n","    memory**:`python     shared_array = mp.Array('i', [1, 2, 3, 4])`\n","\n","4.  **Process synchronization**:\n","```python\n","     lock = mp.Lock()\n","     with lock:\n","      # Critical section`\n","```\n","5.  **Inter-process communication**:\n","```python\n","     queue = mp.Queue()\n","     queue.put('message')\n","     message = queue.get()`\n","```\n","6.  **Process pools with asynchronous results**:\n","```python\n","     async_result = pool.apply_async(worker, (1,))\n","     result = async_result.get(timeout=3)`\n","```\n","\n","### 5. Parallel programming patterns for data processing and analysis in Python Multiprocessing\n","\n","Let’s implement some of the parallel programming patterns discussed earlier using Python’s multiprocessing module:\n","\n","1.  **Map-Reduce Pattern**:\n","\n","``` python\n","import multiprocessing as mp\n","\n","def map_function(x):\n","    return x * x\n","\n","def reduce_function(x, y):\n","    return x + y\n","\n","if __name__ == '__main__':\n","    data = list(range(1, 11))\n","    \n","    with mp.Pool(processes=4) as pool:\n","        # Map phase\n","        mapped_data = pool.map(map_function, data)\n","        \n","        # Reduce phase\n","        result = reduce(reduce_function, mapped_data)\n","    \n","    print(f\"Result: {result}\")\n","```\n","\n","1.  **Fork-Join Pattern**:\n","\n","``` python\n","import multiprocessing as mp\n","\n","def worker(data):\n","    return sum(data)\n","\n","if __name__ == '__main__':\n","    data = list(range(1, 101))\n","    chunk_size = len(data) // 4\n","    \n","    with mp.Pool(processes=4) as pool:\n","        # Fork: Split data into chunks\n","        chunks = [data[i:i+chunk_size] for i in range(0, len(data), chunk_size)]\n","        \n","        # Process chunks in parallel\n","        results = pool.map(worker, chunks)\n","        \n","        # Join: Combine results\n","        final_result = sum(results)\n","    \n","    print(f\"Final result: {final_result}\")\n","```\n","\n","1.  **Pipeline Pattern**:\n","\n","``` python\n","import multiprocessing as mp\n","\n","def stage1(data):\n","    return [x * 2 for x in data]\n","\n","def stage2(data):\n","    return [x + 5 for x in data]\n","\n","def stage3(data):\n","    return sum(data)\n","\n","if __name__ == '__main__':\n","    data = list(range(1, 11))\n","    \n","    with mp.Pool(processes=3) as pool:\n","        # Create a pipeline of stages\n","        result = pool.apply(stage3, args=(pool.apply(stage2, args=(pool.apply(stage1, args=(data,)),)),))\n","    \n","    print(f\"Result: {result}\")\n","```\n","\n","These examples demonstrate how to implement parallel programming patterns using Python’s multiprocessing module for efficient data processing and analysis.\n","\n","## C) Advanced Theory and Practice:\n","\n","### 6. Multiprocessing in Machine Learning and AI\n","Multiprocessing can significantly accelerate machine learning tasks, particularly in data preprocessing, feature engineering, and model training, accelerating tasks such as: <br>\n","-   Parallel data loading and preprocessing\n","-   Distributed model training\n","-   Parallel hyperparameter tuning\n","-   Ensemble methods with parallel model training\n","\n","Example using scikit-learn and joblib:\n","\n","``` python\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.datasets import make_classification\n","from sklearn.model_selection import cross_val_score\n","from joblib import Parallel, delayed\n","import numpy as np\n","\n","# Generate a random classification dataset\n","X, y = make_classification(n_samples=10000, n_features=20, n_classes=2, random_state=42)\n","\n","# Define a function to train and evaluate a model\n","def train_and_evaluate(n_estimators):\n","    clf = RandomForestClassifier(n_estimators=n_estimators, random_state=42)\n","    scores = cross_val_score(clf, X, y, cv=5)\n","    return np.mean(scores)\n","\n","# Parallel hyperparameter tuning\n","n_estimators_list = [10, 50, 100, 200, 500]\n","results = Parallel(n_jobs=-1)(delayed(train_and_evaluate)(n_est) for n_est in n_estimators_list)\n","\n","# Find the best number of estimators\n","best_n_estimators = n_estimators_list[np.argmax(results)]\n","print(f\"Best number of estimators: {best_n_estimators}\")\n","print(f\"Best score: {max(results)}\")\n","```\n","\n","### 7. Best practices and performance optimization techniques\n","\n","To maximize the benefits of multiprocessing, consider the following best\n","practices and optimization techniques:\n","\n","1.  **Choose the right level of parallelism**:\n","\n","    -   Use `multiprocessing.cpu_count()` to determine the number of\n","        available cores.\n","    -   Consider the nature of your tasks (CPU-bound vs. I/O-bound).\n","\n","2.  **Minimize inter-process communication**:\n","\n","    -   Use shared memory for large datasets.\n","    -   Batch communications to reduce overhead.\n","\n","3.  **Use appropriate data structures**:\n","\n","    -   Use `multiprocessing.Array` or `multiprocessing.RawArray` for\n","        shared memory.\n","    -   Consider using `multiprocessing.Manager` for more complex shared\n","        objects.\n","\n","4.  **Optimize task granularity**:\n","\n","    -   Balance the number of tasks with the overhead of creating and\n","        managing processes.\n","\n","5.  **Use process pools**:\n","\n","    -   Reuse processes to avoid the overhead of creating new ones.\n","\n","6.  **Profile your code**:\n","\n","    -   Use tools like cProfile or line_profiler to identify\n","        bottlenecks.\n","\n","7.  **Consider using PyPy for CPU-bound tasks**:\n","\n","    -   PyPy’s JIT compiler can significantly speed up pure Python code.\n","\n","8.  **Use numpy and other optimized libraries**:\n","\n","    -   Leverage libraries that are already optimized for parallel\n","        execution.\n","\n","Example of optimizing task granularity:\n","\n","``` python\n","import multiprocessing as mp\n","import numpy as np\n","\n","def process_chunk(chunk):\n","    return np.sum(chunk ** 2)\n","\n","def parallel_sum_of_squares(data, chunk_size):\n","    pool = mp.Pool()\n","    chunks = [data[i:i+chunk_size] for i in range(0, len(data), chunk_size)]\n","    results = pool.map(process_chunk, chunks)\n","    return sum(results)\n","\n","if __name__ == '__main__':\n","    data = np.random.rand(10**7)\n","    \n","    # Experiment with different chunk sizes\n","    for chunk_size in [10**3, 10**4, 10**5, 10**6]:\n","        result = parallel_sum_of_squares(data, chunk_size)\n","        print(f\"Chunk size: {chunk_size}, Result: {result}\")\n","```\n","\n","### 8. Distributed computing frameworks for large-scale AI applications\n","\n","For large-scale AI applications that require distributed computing\n","across multiple machines, several frameworks are available:\n","\n","1.  **Apache Spark**:\n","\n","    -   Distributed computing framework for big data processing.\n","    -   Supports machine learning through MLlib.\n","\n","2.  **Dask**:\n","\n","    -   Flexible library for parallel computing in Python.\n","    -   Integrates well with existing Python ecosystems (NumPy, Pandas,\n","        Scikit-learn).\n","\n","3.  **Ray**:\n","\n","    -   Distributed computing framework designed for AI applications.\n","    -   Supports distributed training and hyperparameter tuning.\n","\n","4.  **Horovod**:\n","\n","    -   Distributed deep learning training framework.\n","    -   Works with TensorFlow, Keras, PyTorch, and MXNet.\n","\n","Example using Dask for distributed Machine Learning:\n","\n","``` python\n","import dask.dataframe as dd\n","from dask.distributed import Client\n","from dask_ml.model_selection import GridSearchCV\n","from sklearn.ensemble import RandomForestClassifier\n","\n","# Initialize Dask client\n","client = Client()\n","\n","# Load and preprocess data\n","df = dd.read_csv('large_dataset.csv')\n","X = df.drop('target', axis=1)\n","y = df['target']\n","\n","# Define model and parameter grid\n","model = RandomForestClassifier(random_state=42)\n","param_grid = {'n_estimators': [10, 50, 100], 'max_depth': [None, 10, 20]}\n","\n","# Perform distributed grid search\n","grid_search = GridSearchCV(model, param_grid, cv=5)\n","grid_search.fit(X, y)\n","\n","# Print results\n","print(f\"Best parameters: {grid_search.best_params_}\")\n","print(f\"Best score: {grid_search.best_score_}\")\n","```\n","\n","### 9. Quick real-world case studies and practical examples\n","\n","Let’s explore some real-world applications of parallel programming and\n","multiprocessing in data science and AI:\n","\n","1.  **Parallel image processing**:  \n","Process a large dataset of images using multiprocessing to apply     transformations or extract features.\n","\n","``` python\n","import multiprocessing as mp\n","from PIL import Image\n","import os\n","\n","def process_image(image_path):\n","    with Image.open(image_path) as img:\n","        # Apply some transformations\n","        img = img.convert('L')  # Convert to grayscale\n","        img = img.resize((224, 224))  # Resize\n","        return img\n","\n","if __name__ == '__main__':\n","    image_folder = 'path/to/image/folder'\n","    output_folder = 'path/to/output/folder'\n","    \n","    image_paths = [os.path.join(image_folder, f) for f in os.listdir(image_folder) if f.endswith('.jpg')]\n","    \n","    with mp.Pool() as pool:\n","        processed_images = pool.map(process_image, image_paths)\n","    \n","    # Save processed images\n","    for i, img in enumerate(processed_images):\n","        img.save(os.path.join(output_folder, f'processed_{i}.jpg'))\n","```\n","\n","1.  **Parallel text processing for NLP**:  \n","Preprocess a large corpus of text data using multiprocessing to tokenize, clean, and vectorize the text.\n","\n","``` python\n","import multiprocessing as mp\n","import nltk\n","from sklearn.feature_extraction.text import CountVectorizer\n","\n","def preprocess_text(text):\n","    # Tokenize and clean text\n","    tokens = nltk.word_tokenize(text.lower())\n","    tokens = [token for token in tokens if token.isalnum()]\n","    return ' '.join(tokens)\n","\n","if __name__ == '__main__':\n","    corpus = [\n","        \"This is the first document.\",\n","        \"This document is the second document.\",\n","        \"And this is the third one.\",\n","        \"Is this the first document?\",\n","    ]\n","```\n","\n","------------------------------------------------------------------------\n","\n","**Sources:**\n","- [(1) Fundamentals of parallel programming](https://curc.readthedocs.io/en/latest/programming/parallel-programming-fundamentals.html)\n","- [(2) Multi-threading vs Multi-processing programming in Python](https://semfionetworks.com/blog/multi-threading-vs-multi-processing-programming-in-python/)\n","- [(3) Optimize Cross-Validation Time Three Times Faster Using](https://towardsdatascience.com/train-and-test-machine-learning-models-3x-faster-using-multithreading-d8cb0bf9eaf5?gi=ad332718d75c)\n","- [(4) PDF Python Parallel Processing and Multiprocessing: A Review](https://pdfs.semanticscholar.org/7337/73fdf89057322ea78489912c6f769bdfbaff.pdf)\n","- [(5) A Guide to Python Multiprocessing and Parallel Programming](https://www.sitepoint.com/python-multiprocessing-parallel-programming/)\n"],"id":"389bdf46-dfb9-4d8d-a155-761f879031cf"}],"nbformat":4,"nbformat_minor":5,"metadata":{"colab":{"provenance":[]}}}